# AttnDist Kernel 修改需求文档

## 需求场景

修改 `workspace/flash-mla/csrc/sm90/prefill/sparse/attn_dist.cu`，实现类似 `workspace/indexer_loss/indexer_loss_kernel.py` 中计算 attn_dist 的功能。该功能用于计算稀疏注意力分布，将归一化的注意力概率在头维度上求和。

## 核心计算逻辑

参考 `indexer_loss_kernel.py` 中的 `attn_sum_fwd` kernel：
```python
# 已有 lse = log2(sumexp) + m * sm_scale (来自 sparse_mla_fwd)
# 计算 attn_prob = exp2(qk * sm_scale - lse)
# attn_dist = sum(attn_prob, dim=heads)  # 对64个头求和
```

## 输入输出规格

### 输入张量
- `Q`: `[s_q, h_q, d_qk]` - Query张量，bf16格式
- `K`: `[s_kv, h_kv, d_qk]` - Key张量，bf16格式  
- `indices`: `[s_q, h_kv, topk]` - 稀疏索引，int32格式
- `lse`: `[s_q, h_q]` - 预计算的 log-sum-exp 值（log2-based），float32格式

### 输出张量
- `attn_dist`: `[h_q/B_H, s_q, topk]` - 注意力分布，float32格式
  - 对于 128 heads，第一维为 2（每64个头为一组）
  - 维度0 通过不同 thread blocks（由 `q_h_idx` 索引）分别写入
  - 每个位置是该组 64 个头的注意力概率之和

### 参数结构 (已定义在 params.h)
```cpp
struct AttnDistParams {
    int s_q, s_kv, h_q, h_kv, d_qk, topk;
    int q_start_index_s;  // Chunk offset for causal mask
    int k_stride;         // K stride for causal mask
    float sm_scale, sm_scale_div_log2;

    cutlass::bfloat16_t* __restrict__ q;
    cutlass::bfloat16_t* __restrict__ k;
    int* __restrict__ indices;
    float* __restrict__ lse;  // Pre-computed LSE (log2-based)

    int stride_q_s_q; int stride_q_h_q;
    int stride_k_s_kv; int stride_k_h_kv;
    int stride_indices_s_q; int stride_indices_h_kv;

    float* __restrict__ attn_sum;  // Output [2, s_q, topk]
    cudaStream_t stream;
};
```

## 架构技术方案

### 保留的原有机制
1. **双buffer机制**：`plan.k[0]` 和 `plan.k[1]` 两个共享内存缓冲区
2. **三warpgroup架构**（单个 thread block 内）：
   - Warpgroup 0: 消费者，处理**偶数 topk blocks**（block_idx = 0, 2, 4, ...）
   - Warpgroup 1: 消费者，处理**奇数 topk blocks**（block_idx = 1, 3, 5, ...）
   - Warpgroup 2: 生产者，负责异步加载 K 到共享内存
   - **两个 warpgroups 处理相同的 64 个 heads，但交替处理不同的 topk blocks**
3. **Grid 划分**：
   - `grid = ((h_q/B_H) * s_q, 1, 1)`
   - `q_h_idx = blockIdx.x % (h_q/B_H)` 决定处理哪 64 个 heads
   - 对于 128 heads，有 2 个 thread blocks 分别处理 heads 0-63 和 heads 64-127
4. **QK GEMM函数**：
   - `qkt_gemm_one_tile`: 计算单个tile的 Q @ K^T
   - `pipelined_wait_and_qkt_gemm_l`: 等待并计算左半tiles (0-3)
   - `pipelined_wait_and_qkt_gemm_r`: 等待并计算右半tiles (4-8)
   - `pipelined_wait_and_qkt_gemm`: Warpgroup1的完整QK gemm

### 删除的原有逻辑
1. PV GEMM 相关代码（不需要计算 attention @ V）
2. O 输出缓冲区和 store_O 函数
3. online softmax 中的 O 缩放逻辑和 rO 累加
4. **跨 warpgroup 共享注意力分数**（sS0, sS1, wg0_s0_ready, wg1_s1_ready 等同步机制）
5. **跨 warpgroup L 归约**（reduce_L、sL 等）- 原本用于合并两个 warpgroup 的 softmax 分母

### 简化设计说明
由于不需要计算 P @ V，且每个 topk block 的结果可以独立输出：
- **每个 warpgroup 独立处理各自负责的 topk blocks**
- Warpgroup 0 处理偶数 topk blocks：计算 64 个头的 attn_prob 并求和，直接累加到 `attn_dist[q_h_idx, s_q_idx, block_idx*B_TOPK:(block_idx+1)*B_TOPK]`
- Warpgroup 1 处理奇数 topk blocks：同上
- 不需要 warpgroup 间的数据交换（不需要共享 sS0/sS1）
- 仍需保留 K buffer 的生产者-消费者同步

### 新增的计算逻辑
1. **加载 lse**：每个线程加载对应head的 lse 值
2. **计算归一化注意力概率**：
   ```cpp
   // rP 是 QK gemm 的结果 [B_H, B_TOPK] = [64, 64]
   // lse 是预计算的值 [64] (每个head一个)
   // attn_prob = exp2(rP * sm_scale - lse)
   ```
3. **头维度归约**：
   ```cpp
   // 对64个头的 attn_prob 求和
   // attn_dist[topk_idx] = sum(attn_prob[:, topk_idx], dim=0)
   ```
4. **输出 attn_dist**：
   ```cpp
   // 写入 attn_dist[head_group_idx, s_q_idx, topk_idx]
   ```

## 影响文件

| 修改类型 | 文件路径 | 影响的函数/结构 |
|---------|---------|---------------|
| 修改 | `workspace/flash-mla/csrc/sm90/prefill/sparse/attn_dist.cu` | 新增 `attn_dist_kernel` 及 `run_attn_dist_kernel` |

## 详细实现

### 1. SharedMemoryPlan 修改
```cpp
struct AttnDistSharedMemoryPlan {
    // Q 共享内存 (复用原有)
    array_aligned<bf16, cosize_v<SmemLayoutQ>> q;
    // K 双buffer (复用原有)
    array_aligned<bf16, cosize_v<SmemLayoutK>> k[2];
    
    // KV有效性掩码 (复用原有)
    bool is_kv_valid[2][B_TOPK];
    
    // Barriers (简化版，不需要 sS 相关的跨warpgroup同步)
    transac_bar_t bar_q, bar_k0_free[2], bar_k0_ready[2], 
                  bar_k1_free[2], bar_k1_ready[2], bar_is_kv_valid_ready;
    
    // Warpgroup内头维度归约用共享内存
    // 每个 warpgroup 独立使用各自的 buffer
    float attn_dist_reduce[2][B_TOPK];  // [warpgroup_idx][topk_position]
};
```

### 2. 核心kernel函数签名
```cpp
template<typename TmaParams>
__global__ void __launch_bounds__(NUM_THREADS, 1, 1)
attn_dist_kernel(
    __grid_constant__ const AttnDistParams params, 
    __grid_constant__ const TmaParams tma_params
);
```

### 3. Warpgroup 0 计算流程
```cpp
// 1. 加载 Q (复用原有)
// 2. 加载 lse 到寄存器
float lse_local[2];  // 每个线程负责2行

// 3. 双buffer流水线处理每个topk block
for (int block_idx = 0; block_idx < num_topk_blocks; block_idx += 2) {
    // 等待 K 就绪
    pipelined_wait_and_qkt_gemm_l();
    pipelined_wait_and_qkt_gemm_r();
    warpgroup_wait<0>();
    
    // 应用掩码
    mask_rP(Warpgroup0{});
    
    // 计算归一化注意力概率
    // attn_prob = exp2(rP * sm_scale - lse)
    for (int row_idx = 0; row_idx < 2; ++row_idx) {
        for (int i = row_idx*2; i < size(rP); i += 4) {
            rP(i) = exp2f(rP(i) * scale - lse_local[row_idx]);
            rP(i+1) = exp2f(rP(i+1) * scale - lse_local[row_idx]);
        }
    }
    
    // 对64个头求和归约
    // 使用 warp shuffle 进行归约
    ...
}
```

### 4. 头维度归约策略（Warpgroup 内独立归约）

每个 warpgroup 独立处理其负责的 topk block，对 64 个头（行）求和：

**WGMMA 64x64 数据布局分析：**
```cpp
// 128 线程（1 warpgroup = 4 warps × 32 threads），64×64 = 4096 个元素
// 每个线程持有 32 个元素（2 行 × 16 列）

// 行索引计算（get_AorC_row_idx）：
// row_idx = (idx_in_warpgroup/32)*16 + local_row_idx*8 + (idx_in_warpgroup%32/4)
// - (idx_in_warpgroup/32)*16: warp 索引 × 16（每 warp 负责 16 行）
// - local_row_idx*8: 线程内 2 行相隔 8 行
// - (idx_in_warpgroup%32/4): warp 内组索引（0-7），确定具体行

// 列索引计算：
// col_idx = 8*(i/4) + (idx_in_warpgroup%4)*2 + (i%2)
// - 同一 warp 内 4 个连续线程 (t%4 = 0,1,2,3) 持有同一**行**的不同**列**
// - 持有同一**列**的线程索引相差 4：线程 0,4,8,12,16,20,24,28 持有相同的列集合
```

**归约策略关键点：**
- `shfl_xor(1)`, `shfl_xor(2)`: 行内归约（同一行的不同列）— 原代码用于求 max
- `shfl_xor(4)`, `shfl_xor(8)`, `shfl_xor(16)`: **列归约（同一列的不同行）— 头维度求和需要这个**

```cpp
auto reduce_heads_and_store = [&](int block_idx) {
    // Step 1: 每个线程先对自己持有的 2 行（相隔 8 行）在相同列上求和
    // rP layout: 每 4 个元素一组，0,1 属于 row0 的两列，2,3 属于 row1 的相同两列
    float local_sum[16];  // 16 个列位置的部分和
    CUTE_UNROLL
    for (int col_local = 0; col_local < 8; ++col_local) {
        int i_row0 = col_local * 4;      // row 0 的元素起始
        int i_row1 = col_local * 4 + 2;  // row 1 的元素起始
        local_sum[col_local * 2] = rP(i_row0) + rP(i_row1);          // 列 0
        local_sum[col_local * 2 + 1] = rP(i_row0 + 1) + rP(i_row1 + 1);  // 列 1
    }
    // 此时：每个线程持有 16 列的部分和（2 行已合并）
    
    // Step 2: Warp 内列归约（同一列的不同行）
    // 线程 t 和 t^4, t^8, t^16 持有同一列的不同行数据
    // shfl_xor(4), shfl_xor(8), shfl_xor(16) 合并 warp 内 8 组线程
    CUTE_UNROLL
    for (int i = 0; i < 16; ++i) {
        local_sum[i] += __shfl_xor_sync(0xffffffff, local_sum[i], 4);
        local_sum[i] += __shfl_xor_sync(0xffffffff, local_sum[i], 8);
        local_sum[i] += __shfl_xor_sync(0xffffffff, local_sum[i], 16);
    }
    // 此时：warp 内 32 个线程都持有相同的 16 行之和（但持有不同的列）
    // 注意：每个线程仍然只知道自己负责的 16 列
    
    // Step 3: 跨 warp 归约 - 4 个 warp 各持有不同的 16 行
    // 经过 shfl_xor(4,8,16) 后，warp 内每隔 4 的线程持有相同数据
    // 所以每个 warp 只需要前 4 个线程（idx_in_warpgroup % 32 < 4）写入
    // 4 个 warp × 4 个线程 = 16 个线程写入，每线程写 16 列
    //
    // ---- atomicAdd 工作原理说明 ----
    // 
    // 背景：4 个 warp 各自完成了对各自 16 行的归约：
    //   - Warp 0 (idx_in_warpgroup 0-31): 持有行 0-15 的和
    //   - Warp 1 (idx_in_warpgroup 32-63): 持有行 16-31 的和
    //   - Warp 2 (idx_in_warpgroup 64-95): 持有行 32-47 的和
    //   - Warp 3 (idx_in_warpgroup 96-127): 持有行 48-63 的和
    //
    // 列分布：同一 warp 内，线程 0,1,2,3 各负责不同的列集合：
    //   - 线程 t%4=0: 负责列 0,1, 8,9, 16,17, 24,25, 32,33, 40,41, 48,49, 56,57
    //   - 线程 t%4=1: 负责列 2,3, 10,11, 18,19, 26,27, 34,35, 42,43, 50,51, 58,59
    //   - 线程 t%4=2: 负责列 4,5, 12,13, 20,21, 28,29, 36,37, 44,45, 52,53, 60,61
    //   - 线程 t%4=3: 负责列 6,7, 14,15, 22,23, 30,31, 38,39, 46,47, 54,55, 62,63
    //
    // 写入冲突：
    //   - Warp 0 的线程 0 要写入列 0,1,8,9,...
    //   - Warp 1 的线程 0 也要写入列 0,1,8,9,...
    //   - 同样，Warp 2 和 Warp 3 的线程 0 也写相同列
    //   - 这 4 个线程的数据代表不同 16 行的部分和，必须累加才能得到 64 行的总和
    //
    // atomicAdd 作用：
    //   - atomicAdd(&addr, val) 原子地执行 *addr += val
    //   - 保证多线程并发写入同一地址时结果正确（不会丢失更新）
    //   - 此处 4 个 warp 各贡献 16 行的和，最终累加为 64 行的总和
    //
    // 写入模式示意：
    //   attn_dist_reduce[col_0] = warp0_sum[col_0] + warp1_sum[col_0] + warp2_sum[col_0] + warp3_sum[col_0]
    //   （4 次 atomicAdd 操作累加完成）
    //
    if (idx_in_warpgroup % 32 < 4) {
        CUTE_UNROLL
        for (int i = 0; i < 16; ++i) {
            int col_idx = 8 * (i / 2) + (idx_in_warpgroup % 4) * 2 + (i % 2);
            atomicAdd(&plan.attn_dist_reduce[warpgroup_idx][col_idx], local_sum[i]);
        }
    }
    
    // Warpgroup 同步 - 等待所有 4 个 warp 完成写入
    fence_view_async_shared();
    NamedBarrier::arrive_and_wait(128, warpgroup_idx ? NamedBarriers::warpgroup1_sync : NamedBarriers::warpgroup0_sync);
    
    // Step 4: 使用 TMA store 写入全局内存（高效异步写入）
    // 参考 fwd.cu 中 store_O 的实现模式：R→S→G (TMA)
    bool s2g_pred = warp_idx % 4 == 0 && elect_one_sync();  // 每个 warpgroup 选一个线程执行 TMA
    if (s2g_pred) {
        SM90_TMA_STORE_3D::copy(
            &tma_params.tensor_map_attn_dist,
            plan.attn_dist_reduce[warpgroup_idx],  // 共享内存源地址
            block_idx * B_TOPK,                     // topk 维度偏移
            s_q_idx,                                // s_q 维度偏移
            q_h_idx                                 // head_group 维度偏移
        );
    }
    
    // 清零供下一轮使用（所有线程参与，更快）
    if (idx_in_warpgroup < B_TOPK) {
        plan.attn_dist_reduce[warpgroup_idx][idx_in_warpgroup] = 0.0f;
    }
};

// 在所有 topk blocks 处理完毕后，调用 tma_store_arrive 确保写入完成
cute::tma_store_arrive();
```

### 5. run_attn_dist_kernel 函数
```cpp
void run_attn_dist_kernel(const AttnDistParams& params) {
    FLASH_ASSERT(params.h_kv == 1);
    FLASH_ASSERT(params.topk % (2*B_TOPK) == 0);
    FLASH_ASSERT(params.h_q % B_H == 0);

    // 创建 TMA descriptors for Q (load)
    auto shape_Q = make_shape(params.h_q, params.d_qk, params.s_q);
    auto tma_Q = cute::make_tma_copy(
        SM90_TMA_LOAD{},
        make_tensor(
            make_gmem_ptr((bf16*)params.q),
            make_layout(
                shape_Q,
                make_stride(params.stride_q_h_q, _1{}, params.stride_q_s_q)
            )
        ),
        SmemLayoutQ{}
    );

    // 创建 TMA tensor map for attn_dist output (store)
    // attn_dist 形状: [h_q/B_H, s_q, topk]，数据类型: float32
    CUtensorMap tensor_map_attn_dist;
    {
        // 3D tensor: [topk, s_q, h_q/B_H]（列优先）
        uint64_t size[3] = {
            (uint64_t)params.topk,           // dim 0: topk
            (uint64_t)params.s_q,            // dim 1: s_q  
            (uint64_t)(params.h_q / B_H)     // dim 2: head_groups (2 for 128 heads)
        };
        // stride 以字节为单位，从 dim 1 开始
        uint64_t stride[2] = {
            (uint64_t)params.topk * sizeof(float),                      // stride for dim 1
            (uint64_t)params.topk * params.s_q * sizeof(float)          // stride for dim 2
        };
        // box_size: 每次 TMA 操作传输的大小
        uint32_t box_size[3] = {B_TOPK, 1, 1};  // 每次传输 64 个 topk 位置
        uint32_t elem_stride[3] = {1, 1, 1};
        
        CUresult res = CUTLASS_CUDA_DRIVER_WRAPPER_CALL(cuTensorMapEncodeTiled)(
            &tensor_map_attn_dist,
            CUtensorMapDataType::CU_TENSOR_MAP_DATA_TYPE_FLOAT32,  // float32 而非 bf16
            3,
            params.attn_sum,  // 全局内存地址
            size,
            stride,
            box_size,
            elem_stride,
            CUtensorMapInterleave::CU_TENSOR_MAP_INTERLEAVE_NONE,
            CUtensorMapSwizzle::CU_TENSOR_MAP_SWIZZLE_NONE,        // float32 不需要 swizzle
            CUtensorMapL2promotion::CU_TENSOR_MAP_L2_PROMOTION_NONE,
            CUtensorMapFloatOOBfill::CU_TENSOR_MAP_FLOAT_OOB_FILL_NONE
        );
        FLASH_ASSERT(res == CUresult::CUDA_SUCCESS);
    }

    // 打包 TMA 参数
    AttnDistTmaParams<decltype(shape_Q), decltype(tma_Q)> tma_params = {
        shape_Q, tma_Q,
        tensor_map_attn_dist
    };
    
    auto kernel = &attn_dist_kernel<decltype(tma_params)>;
    
    // 配置 kernel launch
    constexpr size_t smem_size = sizeof(AttnDistSharedMemoryPlan);
    CHECK_CUDA(cudaFuncSetAttribute(kernel, cudaFuncAttributeMaxDynamicSharedMemorySize, smem_size));
    
    cutlass::ClusterLaunchParams launch_params = {
        dim3((params.h_q/B_H)*params.s_q, 1, 1),
        dim3(NUM_THREADS, 1, 1),
        dim3(1, 1, 1),
        smem_size,
        params.stream
    };
    
    cutlass::launch_kernel_on_cluster(launch_params, (void*)kernel, params, tma_params);
    CHECK_CUDA_KERNEL_LAUNCH();
}
```

## 边界条件与异常处理

1. **索引有效性检查**：通过 `is_kv_valid` 掩码处理无效索引
2. **因果掩码**：通过 `q_start_index_s` 和 `k_stride` 计算有效 K 范围
3. **数值稳定性**：lse 已经是 log2-based，直接用于 exp2f 计算
4. **边界对齐**：要求 `topk % (2*B_TOPK) == 0` 和 `h_q % B_H == 0`

## 数据流动路径

```
输入:
Q[s_q, h_q, d_qk] → TMA → sQ[B_H, D_Q]
K[s_kv, h_kv, d_qk] → cp.async → sK[B_TOPK, D_K] (双buffer)
lse[s_q, h_q] → load → lse_local[2]
indices[s_q, h_kv, topk] → load → token_indices

计算:
sQ × sK^T → rP[B_H, B_TOPK]  (QK gemm)
attn_prob = exp2(rP * sm_scale - lse)
attn_dist = reduce_sum(attn_prob, dim=heads)

输出:
attn_dist → store → attn_dist[h_q/B_H, s_q, topk]
（不同 thread blocks 通过 q_h_idx 写入不同的 head group 输出）
```

## 预期成果

1. 实现 `attn_dist_kernel` 和 `run_attn_dist_kernel` 函数
2. 保留原有的双buffer和QK gemm架构
3. 正确计算归一化注意力概率并在头维度求和
4. 输出形状为 `[2, s_q, topk]` 的注意力分布
