# _indexer_loss_fused_kernel 算子文档

## 1. 算子概述

`_indexer_loss_fused_kernel` 是一个高度优化的 Triton 融合算子，专为稀疏注意力（Sparse Attention）场景下的 KL 散度 Loss 计算而设计。该算子将 Attention 计算、Softmax 归一化、Head Summation 以及 KL Loss 计算融合在一个 Kernel 中完成，显著减少了显存读写和中间 Tensor 的开销。

### 核心功能
- **稀疏 Attention 计算**: 仅计算 Top-K 个 Key 的 Attention Score，而非全量 Attention。
- **Online Softmax**: 使用 Online Softmax 算法在一次遍历中完成数值稳定的 Softmax 归一化，无需保存全局 Max/Sum。
- **Head Summation**: 直接在 Kernel 内完成多头注意力的概率聚合。
- **KL Divergence**: 计算聚合后的 Attention 分布与 Index Score 分布之间的 KL 散度。
- **Tensor Core 优化**: 利用 `tl.dot` 指令充分利用 Hopper 架构的 Tensor Core 性能。

---

## 2. 接口定义

```python
@triton.jit
def _indexer_loss_fused_kernel(
    Q_ptr, K_ptr, IndexScore_ptr, Indices_ptr, Loss_ptr,
    AttnSum_ptr,  # 中间存储指针
    batch_size, num_heads, chunk_size,
    chunk_offset,
    head_dim: tl.constexpr,
    topk: tl.constexpr,
    scaling,
    eps: tl.constexpr,
    stride_qb, stride_qh, stride_qs, stride_qd,
    stride_kb, stride_ks, stride_kd,
    stride_isb, stride_iss, stride_isk,
    stride_ib, stride_is, stride_ik,
    stride_asb, stride_ass, stride_ask,
    BLOCK_D: tl.constexpr,
    BLOCK_TOPK: tl.constexpr,
    BLOCK_H: tl.constexpr,
)
```

### 参数说明

| 参数名 | 类型 | 说明 |
| :--- | :--- | :--- |
| **指针参数** | | |
| `Q_ptr` | Pointer | Query 张量指针，形状 `[batch, num_heads, chunk_size, head_dim]` |
| `K_ptr` | Pointer | Key 张量指针，形状 `[batch, kv_len, head_dim]` |
| `IndexScore_ptr` | Pointer | Index Score 张量指针，形状 `[batch, chunk_size, topk]` |
| `Indices_ptr` | Pointer | Top-K 索引张量指针，形状 `[batch, chunk_size, topk]` |
| `Loss_ptr` | Pointer | **输出** Loss 张量指针，形状 `[batch, chunk_size]` |
| `AttnSum_ptr` | Pointer | **中间变量** Attention Sum 缓存，形状 `[batch, chunk_size, topk]` |
| **维度参数** | | |
| `batch_size` | int | 批次大小 |
| `num_heads` | int | 注意力头数 |
| `chunk_size` | int | 当前处理的 Query 序列长度 |
| `chunk_offset` | int | 当前 Chunk 在完整序列中的起始位置 (用于 Causal Mask) |
| `head_dim` | int | 每个注意力头的维度 (constexpr) |
| `topk` | int | 每个 Query 选取的 Key 数量 (constexpr) |
| **计算参数** | | |
| `scaling` | float | Attention 缩放因子 (通常为 `1/sqrt(head_dim)`) |
| `eps` | float | 数值稳定性 Epsilon (constexpr) |
| **Strides** | int | 各输入张量的内存步长 (Stride) |
| **Block 配置** | | |
| `BLOCK_D` | int | Head Dim 维度分块大小 (默认 128) |
| `BLOCK_TOPK` | int | Top-K 维度分块大小 (默认 256) |
| `BLOCK_H` | int | Head 维度分块大小 (默认 16) |

---

## 3. 使用限制与注意事项

1.  **硬件要求**: 推荐在 NVIDIA H20 / H100 (Hopper 架构) 上运行，以获得最佳性能。代码中硬编码了部分针对该架构的配置。
2.  **Block 大小限制**:
    - `BLOCK_D` 固定为 128。如果 `head_dim > 128`，算子会自动分块循环处理。
    - `BLOCK_H` 默认为 16。输入 `num_heads` 需要能够被处理或在 Wrapper 层做 Padding (Wrapper 中已处理)。
    - `BLOCK_TOPK` 默认为 256。
3.  **Top-K 限制**: `topk` 必须是 `BLOCK_TOPK` 的倍数或者在调用时正确设置掩码 (当前实现已处理边界情况)。
4.  **中间显存**: 需要分配 `AttnSum` 缓冲区，大小为 `[batch, chunk_size, topk]` (Float32)，远小于全量 Attention Score。

## 4. 调用示例

```python
# 准备数据
batch_size, num_heads, chunk_size, head_dim = 1, 16, 256, 128
topk = 32
query = torch.randn(batch_size, num_heads, chunk_size, head_dim, device='cuda', dtype=torch.bfloat16)
key = torch.randn(batch_size, seq_len, head_dim, device='cuda', dtype=torch.bfloat16)
indices = torch.randint(0, seq_len, (batch_size, chunk_size, topk), device='cuda')
index_score = torch.randn(batch_size, chunk_size, topk, device='cuda', dtype=torch.bfloat16)

# 调用 Wrapper
loss = compute_index_loss_sparse(
    query=query,
    key=key,
    index_score=index_score,
    indices=indices,
    scaling=1.0 / (head_dim ** 0.5),
    chunk_offset=0
)
```

### 4.1 分块处理示例 (Chunk Offset)

当处理长序列（如 KV Cache 长度为 8192，但每次只计算 4096 长度的 Query Chunk）时，需要设置 `chunk_offset` 以确保 Causal Mask 正确。

例如，假设完整序列长度为 `total_seq_len = 8192`，当前正在处理第二个 Chunk（从 4096 到 8191）：

```python
total_seq_len = 8192
chunk_size = 4096
head_dim = 128
topk = 32
batch_size = 1

# 模拟完整的 KV Cache
key_cache = torch.randn(batch_size, total_seq_len, head_dim, device='cuda', dtype=torch.bfloat16)

# 处理第二个 Chunk (Indices 对应后半部分)
# chunk_offset = 4096，表示当前 query[0] 实际上是全局序列的第 4096 个 token
current_chunk_idx = 1
chunk_offset = current_chunk_idx * chunk_size  # 4096

# 当前 Chunk 的 Query
query_chunk = torch.randn(batch_size, num_heads, chunk_size, head_dim, device='cuda', dtype=torch.bfloat16)

# 对应的 Indices 和 Scores (针对该 Chunk)
indices_chunk = torch.randint(0, total_seq_len, (batch_size, chunk_size, topk), device='cuda')
scores_chunk = torch.randn(batch_size, chunk_size, topk, device='cuda', dtype=torch.bfloat16)

loss = compute_index_loss_sparse(
    query=query_chunk,
    key=key_cache,       # 传入完整的 Key
    index_score=scores_chunk,
    indices=indices_chunk,
    scaling=1.0 / (head_dim ** 0.5),
    chunk_offset=chunk_offset  # 关键：设置偏移量
)
```
